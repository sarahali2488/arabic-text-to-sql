{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11049308,"sourceType":"datasetVersion","datasetId":6883364}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport pandas as pd\nimport torch\nfrom transformers import MarianTokenizer, MarianMTModel, BartTokenizer, BartForConditionalGeneration\nfrom pathlib import Path\nimport logging\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T05:58:49.169964Z","iopub.execute_input":"2025-05-21T05:58:49.170472Z","iopub.status.idle":"2025-05-21T05:58:49.174934Z","shell.execute_reply.started":"2025-05-21T05:58:49.170451Z","shell.execute_reply":"2025-05-21T05:58:49.174192Z"},"editable":false},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Set up logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Suppress sacremoses warning\ntry:\n    import sacremoses\nexcept ImportError:\n    logger.warning(\"sacremoses not found, but proceeding as it’s optional for MarianMT.\")\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nlogger.info(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T05:58:49.175648Z","iopub.execute_input":"2025-05-21T05:58:49.175925Z","iopub.status.idle":"2025-05-21T05:58:49.190507Z","shell.execute_reply.started":"2025-05-21T05:58:49.175875Z","shell.execute_reply":"2025-05-21T05:58:49.189793Z"},"editable":false},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Preprocessing","metadata":{"editable":false}},{"cell_type":"markdown","source":"**Splits the dataset into training (80%) and test (20%) sets using random.shuffle for randomization.**","metadata":{"editable":false}},{"cell_type":"code","source":"# train-test split function\ndef custom_train_test_split(data, test_size=0.2, random_state=42):\n    random.seed(random_state)\n    random.shuffle(data)\n    split_idx = int(len(data) * (1 - test_size))\n    train_data = data[:split_idx]\n    test_data = data[split_idx:]\n    return train_data, test_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T05:58:49.192014Z","iopub.execute_input":"2025-05-21T05:58:49.192243Z","iopub.status.idle":"2025-05-21T05:58:49.205187Z","shell.execute_reply.started":"2025-05-21T05:58:49.192224Z","shell.execute_reply":"2025-05-21T05:58:49.204443Z"},"editable":false},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"**Calculates the exact match accuracy between true and predicted SQL queries.**","metadata":{"editable":false}},{"cell_type":"code","source":"# accuracy score function\ndef custom_accuracy_score(true_list, pred_list):\n    matches = sum(1 for t, p in zip(true_list, pred_list) if t == p)\n    return matches / len(true_list) if true_list else 0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T05:58:49.206080Z","iopub.execute_input":"2025-05-21T05:58:49.206334Z","iopub.status.idle":"2025-05-21T05:58:49.220087Z","shell.execute_reply.started":"2025-05-21T05:58:49.206307Z","shell.execute_reply":"2025-05-21T05:58:49.219243Z"},"editable":false},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Model Loading\n##### Loads pre-trained models for translation (MarianMT) and text-to-SQL generation (BART).\n\n* Loads Helsinki-NLP/opus-mt-ar-en (MarianMT) for Arabic-to-English translation using MarianTokenizer and MarianMTModel.\n* Loads facebook/bart-base (BART) for text-to-SQL with BartTokenizer and BartForConditionalGeneration, using trust_remote_code=True to enable generation capabilities","metadata":{"editable":false}},{"cell_type":"code","source":"# Load MarianMT for Arabic-to-English translation\ntranslation_model_name = \"Helsinki-NLP/opus-mt-ar-en\"\ntranslator_tokenizer = MarianTokenizer.from_pretrained(translation_model_name)\ntranslator_model = MarianMTModel.from_pretrained(translation_model_name).to(device)\n\n# Load BART for text-to-SQL with trust_remote_code\nsql_tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\nsql_model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\", trust_remote_code=True).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T05:58:49.221069Z","iopub.execute_input":"2025-05-21T05:58:49.221381Z","iopub.status.idle":"2025-05-21T05:58:51.438241Z","shell.execute_reply.started":"2025-05-21T05:58:49.221353Z","shell.execute_reply":"2025-05-21T05:58:51.437433Z"},"editable":false},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Defninning classes and methods","metadata":{"editable":false}},{"cell_type":"markdown","source":"## Dataset class\nto prepare question-SQL pairs for training the BART model.\n\n__getitem__: Converts a question-SQL pair into tokenized input (input_ids, attention_mask) and target (labels) tensors, padded/truncated to 512 tokens.","metadata":{"editable":false}},{"cell_type":"code","source":"# Dataset for text-to-SQL\nclass SQLDataset(Dataset):\n    def __init__(self, questions, sql_queries, tokenizer, max_length=512):\n        self.questions = questions\n        self.sql_queries = sql_queries\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.questions)\n\n    def __getitem__(self, idx):\n        question = str(self.questions[idx])\n        sql = str(self.sql_queries[idx])\n        input_encoding = self.tokenizer(\n            question,\n            return_tensors=\"pt\",\n            padding=\"max_length\",\n            truncation=True,\n            max_length=self.max_length\n        )\n        target_encoding = self.tokenizer(\n            sql,\n            return_tensors=\"pt\",\n            padding=\"max_length\",\n            truncation=True,\n            max_length=self.max_length\n        )\n        return {\n            \"input_ids\": input_encoding[\"input_ids\"].squeeze(),\n            \"attention_mask\": input_encoding[\"attention_mask\"].squeeze(),\n            \"labels\": target_encoding[\"input_ids\"].squeeze()\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T05:58:51.439030Z","iopub.execute_input":"2025-05-21T05:58:51.439240Z","iopub.status.idle":"2025-05-21T05:58:51.445760Z","shell.execute_reply.started":"2025-05-21T05:58:51.439222Z","shell.execute_reply":"2025-05-21T05:58:51.444932Z"},"editable":false},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## normalization \nNormalizes SQL strings by removing extra whitespace and standardizing commas (e.g., SELECT name , age to SELECT name,age).","metadata":{"editable":false}},{"cell_type":"code","source":"# Function to normalize SQL strings\ndef normalize_sql(sql):\n    import re\n    sql = re.sub(r'\\s+', ' ', sql.strip())\n    sql = re.sub(r'\\s*,\\s*', ',', sql)\n    return sql","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Translates Arabic text to English \nusing MarianMT, logging the input and output.\n\nReturns the translated text.","metadata":{"editable":false}},{"cell_type":"code","source":"# Function to translate Arabic to English\ndef translate_arabic_to_english(text):\n    inputs = translator_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n    inputs = {k: v for k, v in inputs.items() if k != \"token_type_ids\"}\n    translated = translator_model.generate(**inputs, max_length=512)\n    translated_text = translator_tokenizer.decode(translated[0], skip_special_tokens=True)\n    logger.info(f\"Translated '{text}' to '{translated_text}'\")\n    return translated_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T05:58:51.462590Z","iopub.execute_input":"2025-05-21T05:58:51.462802Z","iopub.status.idle":"2025-05-21T05:58:51.470348Z","shell.execute_reply.started":"2025-05-21T05:58:51.462784Z","shell.execute_reply":"2025-05-21T05:58:51.469695Z"},"editable":false},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Generates an SQL query from English text \n\nusing the BART model’s generate method.\n\nReturns the decoded SQL string, logging the process.","metadata":{"editable":false}},{"cell_type":"code","source":"# Function to convert English text to SQL\ndef text_to_sql(english_text, model, tokenizer):\n    inputs = tokenizer(english_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n    with torch.no_grad():\n        outputs = model.generate(**inputs, max_length=512)\n    sql_query = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    logger.info(f\"Generated SQL for '{english_text}': {sql_query}\")\n    return sql_query","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T05:58:51.472512Z","iopub.execute_input":"2025-05-21T05:58:51.472726Z","iopub.status.idle":"2025-05-21T05:58:51.483492Z","shell.execute_reply.started":"2025-05-21T05:58:51.472710Z","shell.execute_reply":"2025-05-21T05:58:51.482840Z"},"editable":false},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Combines translation and SQL generation for an Arabic query.\nReturns the English translation and generated SQL.","metadata":{"editable":false}},{"cell_type":"code","source":"# Function to process a single query\ndef process_query(arabic_question, model, tokenizer):\n    english_question = translate_arabic_to_english(arabic_question)\n    sql_query = text_to_sql(english_question, model, tokenizer)\n    return english_question, sql_query\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T05:58:51.484226Z","iopub.execute_input":"2025-05-21T05:58:51.484490Z","iopub.status.idle":"2025-05-21T05:58:51.496317Z","shell.execute_reply.started":"2025-05-21T05:58:51.484467Z","shell.execute_reply":"2025-05-21T05:58:51.495628Z"},"editable":false},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Data Loading and Splitting","metadata":{"editable":false}},{"cell_type":"code","source":"# Load dataset\ndataset_path = \"/kaggle/input/txttosql-nlp/AR_spider.jsonl\"\ndata = []\nif not Path(dataset_path).exists():\n    raise FileNotFoundError(f\"Dataset not found at {dataset_path}. Please ensure the file exists.\")\nwith open(dataset_path, 'r', encoding='utf-8') as f:\n    for line in f:\n        data.append(json.loads(line.strip()))\n\n# Convert to DataFrame\ndf = pd.DataFrame(data)\nlogger.info(f\"Loaded {len(df)} queries from dataset.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T05:58:51.497052Z","iopub.execute_input":"2025-05-21T05:58:51.497329Z","iopub.status.idle":"2025-05-21T05:58:51.561427Z","shell.execute_reply.started":"2025-05-21T05:58:51.497301Z","shell.execute_reply":"2025-05-21T05:58:51.560641Z"},"editable":false},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Split dataset into train and test\ntrain_data, test_data = custom_train_test_split(data, test_size=0.2, random_state=42)\ntrain_df = pd.DataFrame(train_data)\ntest_df = pd.DataFrame(test_data)\nlogger.info(f\"Training set: {len(train_df)} samples, Test set: {len(test_df)} samples\")\n\n# Prepare training data\ntrain_questions = train_df['question'].tolist()\ntrain_sqls = train_df['query'].tolist()\ntrain_dataset = SQLDataset(train_questions, train_sqls, sql_tokenizer)\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T05:58:51.562235Z","iopub.execute_input":"2025-05-21T05:58:51.562478Z","iopub.status.idle":"2025-05-21T05:58:51.587545Z","shell.execute_reply.started":"2025-05-21T05:58:51.562455Z","shell.execute_reply":"2025-05-21T05:58:51.586774Z"},"editable":false},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Model Training\nFine-tunes the BART model on the training data for 10 epochs.\n\n* Uses AdamW optimizer with a learning rate of 2e-5.\n* Trains for 10 epochs (changed from 3), processing batches and computing loss.\n* Logs the average loss per epoch and switches the model to evaluation mode after training.","metadata":{"editable":false}},{"cell_type":"code","source":"# Fine-tune BART model\noptimizer = torch.optim.AdamW(sql_model.parameters(), lr=2e-5)\nsql_model.train()\nlogger.info(\"Starting fine-tuning BART for text-to-SQL...\")\nfor epoch in range(10):  # Changed from 3 to 10 epochs\n    total_loss = 0\n    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n        \n        outputs = sql_model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        total_loss += loss.item()\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n    logger.info(f\"Epoch {epoch+1} Loss: {total_loss / len(train_loader):.4f}\")\n\nsql_model.eval()\nlogger.info(\"Fine-tuning completed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T05:58:51.588375Z","iopub.execute_input":"2025-05-21T05:58:51.588726Z","iopub.status.idle":"2025-05-21T07:28:57.721555Z","shell.execute_reply.started":"2025-05-21T05:58:51.588706Z","shell.execute_reply":"2025-05-21T07:28:57.720904Z"},"editable":false},"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 640/640 [09:00<00:00,  1.18it/s]\nEpoch 2: 100%|██████████| 640/640 [09:00<00:00,  1.18it/s]\nEpoch 3: 100%|██████████| 640/640 [09:00<00:00,  1.18it/s]\nEpoch 4: 100%|██████████| 640/640 [09:00<00:00,  1.18it/s]\nEpoch 5: 100%|██████████| 640/640 [09:00<00:00,  1.18it/s]\nEpoch 6: 100%|██████████| 640/640 [09:00<00:00,  1.18it/s]\nEpoch 7: 100%|██████████| 640/640 [09:00<00:00,  1.18it/s]\nEpoch 8: 100%|██████████| 640/640 [09:00<00:00,  1.18it/s]\nEpoch 9: 100%|██████████| 640/640 [09:00<00:00,  1.18it/s]\nEpoch 10: 100%|██████████| 640/640 [09:00<00:00,  1.18it/s]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# Model Evaluation\n\nEvaluates the fine-tuned model on the test set.\n\n* Defines evaluate_system(test_data, model, tokenizer, num_samples=None) to process up to 100 test samples.\n* Generates SQL for each Arabic query, normalizes true and predicted SQL, and computes accuracy.\n* Logs details and prints mismatches (up to 10).","metadata":{"editable":false}},{"cell_type":"code","source":"# Evaluate system accuracy\ndef evaluate_system(test_data, model, tokenizer, num_samples=None):\n    true_sqls = []\n    pred_sqls = []\n    \n    samples = test_data[:num_samples] if num_samples else test_data\n    \n    for i, item in enumerate(tqdm(samples, desc=\"Evaluating\")):\n        arabic_q = item['arabic']\n        true_sql = item['query']\n        \n        english_q, pred_sql = process_query(arabic_q, model, tokenizer)\n        \n        true_sql_norm = normalize_sql(true_sql)\n        pred_sql_norm = normalize_sql(pred_sql)\n        \n        true_sqls.append(true_sql_norm)\n        pred_sqls.append(pred_sql_norm)\n        \n        logger.info(f\"Sample {i+1}: Arabic: {arabic_q}, English: {english_q}, True SQL: {true_sql_norm}, Predicted SQL: {pred_sql_norm}\")\n    \n    accuracy = custom_accuracy_score(true_sqls, pred_sqls)\n    return accuracy, true_sqls, pred_sqls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T07:28:57.722318Z","iopub.execute_input":"2025-05-21T07:28:57.722576Z","iopub.status.idle":"2025-05-21T07:28:57.727806Z","shell.execute_reply.started":"2025-05-21T07:28:57.722559Z","shell.execute_reply":"2025-05-21T07:28:57.727270Z"},"editable":false},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Run evaluation on test set\ntry:\n    accuracy, true_sqls, pred_sqls = evaluate_system(test_data, sql_model, sql_tokenizer, num_samples=min(len(test_data), 100))\n    print(f\"System Accuracy (on {min(len(test_data), 100)} test samples): {accuracy:.2f}\")\n    mismatches = [(i, t, p) for i, (t, p) in enumerate(zip(true_sqls, pred_sqls)) if t != p][:10]\n    for i, true, pred in mismatches:\n        print(f\"Mismatch in sample {i+1}:\")\n        print(f\"  True SQL: {true}\")\n        print(f\"  Predicted SQL: {pred}\")\nexcept Exception as e:\n    print(f\"Error during evaluation: {e}\")\n\n# Test with example queries\ntest_queries = [\n    \"كم عدد رؤساء الأقسام الذين تزيد أعمارهم عن 56 سنة؟\",\n    \"ما هي أسماء الأقسام التي لديها أكثر من 10 موظفين؟\",\n    \"كم عدد الموظفين في قسم المبيعات؟\"\n]\n\nprint(\"\\nTesting multiple queries:\")\nfor q in test_queries:\n    eng, sql = process_query(q, sql_model, sql_tokenizer)\n    print(f\"\\nArabic: {q}\")\n    print(f\"English: {eng}\")\n    print(f\"SQL: {sql}\")\n\nprint(\"\\nNote: The text-to-SQL model is fine-tuned on the dataset using BART for 10 epochs. \"\n      \"Accuracy depends on training data size and query diversity. Ensure scikit-learn>=1.5.2 is installed if sklearn is needed elsewhere.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-21T04:27:23.622072Z","iopub.execute_input":"2025-05-21T04:27:23.622361Z","iopub.status.idle":"2025-05-21T05:58:49.168647Z","shell.execute_reply.started":"2025-05-21T04:27:23.622328Z","shell.execute_reply":"2025-05-21T05:58:49.167930Z"},"editable":false},"outputs":[{"name":"stderr","text":"2025-05-21 04:27:38.329234: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747801658.521150      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747801658.576284      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e5c8b43c5cd47b58f0b9aa7b4baff3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/917k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f7da3022acc4990a81961c197b94224"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae5f50ad3b8b453395fdeac8a5f12675"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.13M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7199e6bd437c44b49c264e7899298f88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f424d6ce52e84dceb9397256676d4853"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/308M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"546497da862f4938a332b74653d826bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"599583d746b447258964bc46465c08ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c600e31c8f5471695162a3d450ab893"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61936f36be344ac68070bb09d3799d2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8770887b2d4740658cba7da99cf08ce2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"899544b1d3684cdb9e5efc84fbced59b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55eaa40564ef49178cfa4ac45700de62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5847f40a2a164cdcb844a6becc88dfaf"}},"metadata":{}},{"name":"stderr","text":"Epoch 1: 100%|██████████| 640/640 [08:59<00:00,  1.19it/s]\nEpoch 2: 100%|██████████| 640/640 [08:59<00:00,  1.19it/s]\nEpoch 3: 100%|██████████| 640/640 [08:59<00:00,  1.19it/s]\nEpoch 4: 100%|██████████| 640/640 [08:59<00:00,  1.19it/s]\nEpoch 5: 100%|██████████| 640/640 [08:59<00:00,  1.19it/s]\nEpoch 6: 100%|██████████| 640/640 [09:00<00:00,  1.19it/s]\nEpoch 7: 100%|██████████| 640/640 [08:59<00:00,  1.19it/s]\nEpoch 8: 100%|██████████| 640/640 [09:00<00:00,  1.19it/s]\nEpoch 9: 100%|██████████| 640/640 [09:00<00:00,  1.18it/s]\nEpoch 10: 100%|██████████| 640/640 [09:00<00:00,  1.18it/s]\nEvaluating: 100%|██████████| 100/100 [00:48<00:00,  2.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"System Accuracy (on 100 test samples): 0.03\nMismatch in sample 2:\n  True SQL: SELECT Planned_Delivery_Date,Actual_Delivery_Date FROM BOOKINGS\n  Predicted SQL: SELECT T1.prereq_date,T2.date_of_delivery FROM Reservations AS T1 JOIN Delivery_Roles AS T2 ON T3.Reservation_ID = T4.Resident_ID\nMismatch in sample 3:\n  True SQL: SELECT T2.lot_details FROM INVESTORS AS T1 JOIN LOTS AS T2 ON T1.investor_id = T2.investor_id WHERE T1.Investor_details = \"l\"\n  Predicted SQL: SELECT T1.purchase_details FROM purchase_transactions AS T1 JOIN TRANSACTIONS AS T2 ON T2.transaction_id = T3.transactions_id WHERE T3,amount_purchased > 10000\nMismatch in sample 4:\n  True SQL: SELECT T2.balance FROM accounts AS T1 JOIN checking AS T2 ON T1.custid = T2.custid WHERE T1.name IN (SELECT T1.name FROM accounts AS T1 JOIN savings AS T2 ON T1.custid = T2.custid WHERE T2.balance > (SELECT avg(balance) FROM savings))\n  Predicted SQL: SELECT T2.balance FROM accounts AS T1 JOIN savings AS T2 ON T1.council_id = T2;\nMismatch in sample 5:\n  True SQL: SELECT t3.title FROM authors AS t1 JOIN authorship AS t2 ON t1.authid = t2.authid JOIN papers AS t3 ON t2.paperid = t3.paperid WHERE t1.fname = \"Olin\" AND t1.lname = \"Shivers\"\n  Predicted SQL: SELECT t3.title FROM authors AS t1 JOIN authorship AS t2 ON t1.authid = t2.authhip_id JOIN papers AS t3 ON t4.paperid > t5.letterid WHERE t 1.fname = \"Olain Schaeffers\"\nMismatch in sample 6:\n  True SQL: SELECT pName FROM Player WHERE yCard = 'yes' ORDER BY HS DESC\n  Predicted SQL: SELECT DISTINCT cName FROM experiment ORDER BY cName\nMismatch in sample 7:\n  True SQL: SELECT Song FROM volume WHERE Weeks_on_Top > 1\n  Predicted SQL: SELECT song FROM vocals WHERE duration > (SELECT max(duration) FROM vocals)\nMismatch in sample 8:\n  True SQL: SELECT campus FROM degrees GROUP BY campus ORDER BY sum(degrees) DESC LIMIT 1\n  Predicted SQL: SELECT cName FROM degrees GROUP BY cName ORDER BY sum(degrees) DESC LIMIT 1\nMismatch in sample 9:\n  True SQL: SELECT DISTINCT T1.firstname,T1.lastname FROM list AS T1 JOIN teachers AS T2 ON T1.classroom = T2.classroom WHERE T1.grade = 1 EXCEPT SELECT T1.firstname,T1.lastname FROM list AS T1 JOIN teachers AS T2 ON T1.classroom = T2.classroom WHERE T2.firstname = \"OTHA\" AND T2.lastname = \"MOYER\"\n  Predicted SQL: SELECT DISTINCT T2.name FROM list AS T1 JOIN teachers AS T2 ON T1.classroom = T2.'classroom WHERE grade < 3\nMismatch in sample 10:\n  True SQL: SELECT cName,enr FROM College WHERE enr > 10000 AND state = \"LA\"\n  Predicted SQL: SELECT * FROM College ORDER BY Number_of_registrations DESC\nMismatch in sample 12:\n  True SQL: SELECT count(*) FROM Songs\n  Predicted SQL: SELECT T3.Title FROM Performance AS T1 JOIN Band AS T2 ON T1.bandmate = T2.id WHERE lastname = \"Helo\"\n\nTesting multiple queries:\n\nArabic: كم عدد رؤساء الأقسام الذين تزيد أعمارهم عن 56 سنة؟\nEnglish: How many department heads are over 56 years old?\nSQL: SELECT count(*) FROM department WHERE age  >  56\n\nArabic: ما هي أسماء الأقسام التي لديها أكثر من 10 موظفين؟\nEnglish: What are the names of the departments that have more than 10 employees?\nSQL: SELECT DName FROM DEPARTMENT GROUP BY DName HAVING COUNT(*)  >  10\n\nArabic: كم عدد الموظفين في قسم المبيعات؟\nEnglish: How many employees in the sales department?\nSQL: SELECT count(*) FROM employees WHERE department_name  =  \"Sales\"\n\nNote: The text-to-SQL model is fine-tuned on the dataset using BART for 10 epochs. Accuracy depends on training data size and query diversity. Ensure scikit-learn>=1.5.2 is installed if sklearn is needed elsewhere.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null}]}